# configs/model/qwen3_omni_70b_moe.yaml

model_type: qwen3_omni_moe

# 基本结构
vocab_size: 152064        # 可以根据实际 tokenizer 调整
hidden_size: 8192
intermediate_size: 21760
num_hidden_layers: 64
num_attention_heads: 64
num_key_value_heads: 8    # 使用 GQA：64 / 8 = 8 heads per KV
max_position_embeddings: 4096

# 多模态相关占位（与 7B 版本对齐）
image_token_id: 151857
audio_token_id: 151858
video_token_id: 151859
audio_start_token_id: 151860
audio_end_token_id: 151861

# RoPE（保持大 theta 但加上统一的 scaling 字段）
rope_theta: 1000000.0
rope_scaling:
  type: "linear"
  factor: 1.0

# Thinker 子配置（Text / Vision / Audio）
thinker_config:
  hidden_size: 8192
  intermediate_size: 21760
  num_hidden_layers: 64
  num_attention_heads: 64
  num_key_value_heads: 8
  max_position_embeddings: 4096

  use_moe: true
  num_experts: 16
  num_experts_per_tok: 2
  moe_layer_indices: "4,8,12,16,20,24,28,32,36,40,44,48,52,56,60"
  moe_aux_loss_coef: 0.02
  use_shared_expert: true
  shared_intermediate_size: 4096
  moe_router_init_std: 1e-2
  moe_router_normalize_init: true
  moe_renormalize_topk: true

  use_flash_attention: true
  headwise_attn_output_gate: true
  elementwise_attn_output_gate: false

  # DeltaNet / Hybrid attention 配置（默认关闭） 
  use_deltanet: true
  deltanet_layer_indices: ""   # 为空走默认 3:1 模式；可显式列出层索引
  deltanet_kernel_size: 3
  deltanet_num_heads: 64
  deltanet_chunk_size: 0


  # 视觉/音频 backbone 尺度先保持与 7B 对齐，后续可独立替换为具体 ViT / AudioEncoder 配置
  vision_hidden_size: 1152
  audio_hidden_size: 1024

# Talker 子配置占位（先复用 7B 的轻量配置，减少语音解码侧参数量）
talker_config:
  hidden_size: 1536
  num_hidden_layers: 12
  num_attention_heads: 24
  num_code_groups: 8
  codebook_size: 1024
  accept_hidden_layer: -1   # 使用 Thinker 最后一层 hidden state

# Code2Wav 子配置占位（同样先与 7B 对齐）
code2wav_config:
  hidden_size: 1024
  num_layers: 12
  kernel_size: 5
  stride: 2

# 其它 tokenizer 相关
bos_token_id: 151643
eos_token_id: 151645
pad_token_id: 151643
